64 the primary decomposition theorem we be try to study a linear operator t on the finite-dimensional space v by decompose t into a direct sum of operator which be in some sense elementary we can do this through the characteristic value and vector of t in certain special case ie when the minimal polynomial for t factor over the scalar field f into a product of distinct monic polynomial of degree 1 what can we do with the general t if we try to study t use characteristic value we be confront with two problem first t may not have a single characteristic value this be really a deficiency in the scalar field namely that it be not algebraically close second even if the characteristic polynomial factor completely over f into a product of polynomial of degree 1 there may not be enough characteristic vector for t to span the space v this be clearly a deficiency in t the second situation be illustrate by the operator t on afj f any field represent in the standard basis by afj the characteristic polynomial for a be afj and this be plainly also the minimal polynomial for a or for t thus t be not diagonalizable one see that this happen because the null space of afj have dimension 1 only on the other hand the null space of afj and the null space of afj together span v the former be the subspace span by afj and the latter the subspace span by afj and afj this will be more or less we general method for the second problem if remember this be an assumption the minimal polynomial for t decompose afj where afj be distinct element of f then we shall show that the space v be the direct sum of the null space of afj the diagonalizable operator be the special case of this in which afj for each i the theorem which we prove be more general than what we have describe since it work with the primary decomposition of the minimal polynomial whether or not the prime which enter be all of first degree the reader will find it helpful to think of the special case when the prime be of degree 1 and even more particularly to think of the proof of theorem 10 a special case of this theorem theorem 12 primary decomposition theorem let t be a linear operator on the finite-dimensional vector space v over the field f let p be the minimal polynomial for t afj where the afj be distinct irreducible monic polynomial over f and the afj be positive integer let afj be the null space of afj then a afj b each afj be invariant under t c if afj be the operator induce on afj by t then the minimal polynomial for afj be afj proof the idea of the proof be this if the direct-sum decomposition a be valid how can we get hold of the projection afj associate with the decomposition the projection afj will be the identity on afj and zero on the other afj we shall find a polynomial afj such that afj be the identity on afj and be zero on the other afj and so that afj etc for each i let afj since afj be distinct prime polynomial the polynomial afj be relatively prime theorem 8 chapter 4 thus there be polynomial afj such that afj note also that if afj then afj be divisible by the polynomial p because afj contain each afj a a factor we shall show that the polynomial afj behave in the manner describe in the first paragraph of the proof let afj since afj and p divide afj for afj we have afj thus the afj be projection which correspond to some direct-sum decomposition of the space v we wish to show that the range of afj be exactly the subspace afj it be clear that each vector in the range of afj be in afj for if \*\* you be in the range of afj then afj and so afj because afj be divisible by the minimal polynomial p conversely suppose that \*\* you be in the null space of afj if afj then afj be divisible by afj and so afj ie afj but then it be immediate that afj ie that \*\* you be in the range of afj this complete the proof of statement a it be certainly clear that the subspaces afj be invariant under t if afj be the operator induce on afj by t then evidently afj because by definition afj be 0 on the subspace afj this show that the minimal polynomial for afj divide afj conversely let g be any polynomial such that afj then afj thus afj be divisible by the minimal polynomial p of t ie afj divide afj it be easily see that afj divide g hence the minimal polynomial for afj be afj corollary if afj be the projection associate with the primary decomposition of t then each afj be a polynomial in t and accordingly if a linear operator u commute with t then u commute with each of the afj ie each subspace afj be invariant under u in the notation of the proof of theorem 12 let we take a look at the special case in which the minimal polynomial for t be a product of first-degree polynomial ie the case in which each afj be of the form afj now the range of afj be the null space afj of afj let we put afj by theorem 10 d be a diagonalizable operator which we shall call the diagonalizable part of t let we look at the operator afj now afj afj so afj the reader should be familiar enough with projection by now so that he see that afj and in general that afj when afj for each i we shall have afj because the operator afj will then be 0 on the range of afj definition let n be a linear operator on the vector space v we say that n be nilpotent if there be some positive integer r such that afj theorem 13 let t be a linear operator on the finite-dimensional vector space v over the field f suppose that the minimal polynomial for t decompose over f into a product of linear polynomial then there be a diagonalizable operator d on v and a nilpotent operator n in v such that a afj b afj the diagonalizable operator d and the nilpotent operator n be uniquely determine by a and b and each of they be a polynomial in t proof we have just observe that we can write afj where d be diagonalizable and n be nilpotent and where d and n not only commute but be polynomial in t now suppose that we also have afj where d be diagonalizable n be nilpotent and afj we shall prove that afj since d and n commute with one another and afj we see that d and n commute with t thus d and n commute with any polynomial in t hence they commute with d and with n now we have afj or afj and all four of these operator commute with one another since d and d be both diagonalizable and they commute they be simultaneously diagonalizable and afj be diagonalizable since n and n be both nilpotent and they commute the operator afj be nilpotent for use the fact that n and n commute afj and so when r be sufficiently large every term in this expression for afj will be 0 actually a nilpotent operator on an n-dimensional space must have it t power 0 if we take afj above that will be large enough it then follow that afj be large enough but this be not obvious from the above expression now afj be a diagonalizable operator which be also nilpotent such an operator be obviously the zero operator for since it be nilpotent the minimal polynomial for this operator be of the form afj for some afj but then since the operator be diagonalizable the minimal polynomial can not have a repeat root hence afj and the minimal polynomial be simply x which say the operator be 0 thus we see that afj and afj corollary let v be a finite-dimensional vector space over an algebraically close field f eg the field of complex number then every linear operator t in v can be write a the sum of a diagonalizable operator d and a nilpotent operator n which commute these operator d and n be unique and each be a polynomial in t from these result one see that the study of linear operator on vector space over an algebraically close field be essentially reduce to the study of nilpotent operator for vector space over non-algebraically close field we still need to find some substitute for characteristic value and vector it be a very interest fact that these two problem can be handle simultaneously and this be what we shall do in the next chapter in conclude this section we should like to give an example which illustrate some of the idea of the primary decomposition theorem we have choose to give it at the end of the section since it deal with differential equation and thus be not purely linear algebra example 11 in the primary decomposition theorem it be not necessary that the vector space v be finite dimensional nor be it necessary for part a and b that p be the minimal polynomial for t if t be a linear operator on an arbitrary vector space and if there be a monic polynomial p such that afj then part a and b of theorem 12 be valid for t with the proof which we give let n be a positive integer and let v be the space of all n time continuously differentiable function f on the real line which satisfy the differential equation afj where afj be some fix constant if afj denote the space of n time continuously differentiable function then the space v of solution of this differential equation be a subspace of afj if d denote the differentiation operator and p be the polynomial afj then v be the null space of the operator p because afj simply say afj let we now regard d a a linear operator on the subspace v then afj if we be discuss differentiable complex-valued function then afj and v be complex vector space and afj may be any complex number we now write afj where afj be distinct complex number if afj be the null space of afj then theorem 12 say that afj in other word if f satisfy the differential equation afj then f be uniquely expressible in the form afj where afj satisfy the differential equation afj thus the study of the solution to the equation afj be reduce to the study of the space of solution of a differential equation of the form afj this reduction have be accomplish by the general method of linear algebra ie by the primary decomposition theorem to describe the space of solution to afj one must know something about differential equation that be one must know something about d other than the fact that it be a linear operator however one do not need to know very much it be very easy to establish by induction on r that if f be in afj then afj that be afj etc thus afj if and only if afj a function g such that afj ie afj must be a polynomial function of degree afj or less afj thus f satisfy afj if and only if f have the form afj accordingly the function afj span the space of solution of afj since afj be linearly independent function and the exponential function have no zero these r function afj form a basis for the space of solution 